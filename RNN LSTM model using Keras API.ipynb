{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Stateful model with Keras - long-term dependencies understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIbraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "from keras.utils import * \n",
    "from keras.layers import TimeDistributed, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://psv4.userapi.com/c834700/u7402511/docs/d10/49ffe7ed6ef1/Kaspersky.txt\n",
      "49152/45212 [================================] - 0s 9us/step\n",
      "Corpus lengh:  45115\n"
     ]
    }
   ],
   "source": [
    "path = get_file('kaspersky.txt', origin=\"https://psv4.userapi.com/c834700/u7402511/docs/d10/49ffe7ed6ef1/Kaspersky.txt\")\n",
    "text = open(path).read()\n",
    "print('Corpus lengh: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flexible fingerprint for detection of malware\n",
      "US 8955120 B2\n",
      "ABSTRACT\n",
      "System and method for analyzing a target object for similarity to classes of reference objects. A first and a second set of attributes of the target object is identified composed respectively of attributes having values that are common, and variable, among a class of similar objects. A first hash is computed representing the first set of attributes according to a first hashing algorithm that is sensitive to variations in the first set of attributes among the class of similar objects. A second hash representing the second set of attributes is computed according to a second hashing algorithm that is insensitive to variations in the second set of attributes among the class of similar objects. An aggregate representation of the target object that is based on the first hash and the second hash is generated.\n",
      "DESCRIPTION\n",
      "CLAIM TO PRIORITY\n",
      "The Application claims priority to Russian Federation Patent Application No. 2013129552\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding unique characters, converting to string, mapping, index converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique chars:  80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n '()*,-./0123456789:;ABCDEFGHIJKLMNOPRSTUVWXYZ\\\\_abcdefghijklmnopqrstuvwxyz«®—“”\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"Total unique chars: \", vocab_size)\n",
    "''.join(chars[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map from chars to indices and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, \"'\": 2, '(': 3, ')': 4, '*': 5, ',': 6, '-': 7, '.': 8, '/': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, 'A': 22, 'B': 23, 'C': 24, 'D': 25, 'E': 26, 'F': 27, 'G': 28, 'H': 29, 'I': 30, 'J': 31, 'K': 32, 'L': 33, 'M': 34, 'N': 35, 'O': 36, 'P': 37, 'R': 38, 'S': 39, 'T': 40, 'U': 41, 'V': 42, 'W': 43, 'X': 44, 'Y': 45, 'Z': 46, '\\\\': 47, '_': 48, 'a': 49, 'b': 50, 'c': 51, 'd': 52, 'e': 53, 'f': 54, 'g': 55, 'h': 56, 'i': 57, 'j': 58, 'k': 59, 'l': 60, 'm': 61, 'n': 62, 'o': 63, 'p': 64, 'q': 65, 'r': 66, 's': 67, 't': 68, 'u': 69, 'v': 70, 'w': 71, 'x': 72, 'y': 73, 'z': 74, '«': 75, '®': 76, '—': 77, '“': 78, '”': 79}\n",
      "{0: '\\n', 1: ' ', 2: \"'\", 3: '(', 4: ')', 5: '*', 6: ',', 7: '-', 8: '.', 9: '/', 10: '0', 11: '1', 12: '2', 13: '3', 14: '4', 15: '5', 16: '6', 17: '7', 18: '8', 19: '9', 20: ':', 21: ';', 22: 'A', 23: 'B', 24: 'C', 25: 'D', 26: 'E', 27: 'F', 28: 'G', 29: 'H', 30: 'I', 31: 'J', 32: 'K', 33: 'L', 34: 'M', 35: 'N', 36: 'O', 37: 'P', 38: 'R', 39: 'S', 40: 'T', 41: 'U', 42: 'V', 43: 'W', 44: 'X', 45: 'Y', 46: 'Z', 47: '\\\\', 48: '_', 49: 'a', 50: 'b', 51: 'c', 52: 'd', 53: 'e', 54: 'f', 55: 'g', 56: 'h', 57: 'i', 58: 'j', 59: 'k', 60: 'l', 61: 'm', 62: 'n', 63: 'o', 64: 'p', 65: 'q', 66: 'r', 67: 's', 68: 't', 69: 'u', 70: 'v', 71: 'w', 72: 'x', 73: 'y', 74: 'z', 75: '«', 76: '®', 77: '—', 78: '“', 79: '”'}\n"
     ]
    }
   ],
   "source": [
    "char_indices = dict((c,i) for i,c in enumerate(chars))\n",
    "indices_char = dict((i,c) for i,c in enumerate(chars))\n",
    "print(char_indices)\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idx as character to index converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 60, 53, 72, 57, 50, 60, 53, 1, 54]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Flexible fingerprint for detection of malware\\nUS 8955120 B2\\nABSTRACT\\nSystem and '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "print(idx[:10])\n",
    "''.join(indices_char[i] for i in idx[:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number sentences:  45076\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40 #splitting into the chunks of 40\n",
    "sentences = []\n",
    "next_char = []\n",
    "for i in range(0, len(idx)-maxlen+1):\n",
    "    sentences.append(idx[i: i+maxlen])\n",
    "    next_char.append(idx[i+1: i+maxlen+1])\n",
    "print('Number sentences: ', len(sentences))                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy array of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27 60 53 72 57 50 60 53  1 54 57 62 55 53 66 64 66 57 62 68  1 54 63 66\n",
      "   1 52 53 68 53 51 68 57 63 62  1 63 54  1 61 49]]\n",
      "[[60 53 72 57 50 60 53  1 54 57 62 55 53 66 64 66 57 62 68  1 54 63 66  1\n",
      "  52 53 68 53 51 68 57 63 62  1 63 54  1 61 49 60]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((45074, 40), (45074, 40))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_2 = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_char_2 = np.concatenate([[np.array(o)] for o in next_char[:-2]])\n",
    "print(sentences_2[:1])\n",
    "print(next_char_2[:1])\n",
    "sentences_2.shape, next_char_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=maxlen), #embeddings already in RNN Keras model\n",
    "    BatchNormalization(),\n",
    "    LSTM(512, return_sequences=True), # stateful as additional parameter #return_sequences=True -making RNN\n",
    "    Dropout(0.2),\n",
    "    TimeDistributed(Dense(vocab_size)),\n",
    "    Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 40, 24)            1920      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 40, 24)            96        \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 40, 512)           1099776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 40, 80)            41040     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40, 80)            0         \n",
      "=================================================================\n",
      "Total params: 1,142,832\n",
      "Trainable params: 1,142,784\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string='malware detection can based on procedure'\n",
    "    for i in range(320):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-40:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1] #model.predict(x)\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "45074/45074 [==============================] - 3135s 70ms/step - loss: 1.3970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3f8eee4a20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences_2, np.expand_dims(next_char_2, -1), batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malware detection can based on proceduresh interfaces) in program in ard wilith beed. The extrive, disgling that is considered to be similar to the files from a subset of attributes containiret between fuch, a maticious, with a set of attributes accosing the drofen ndoursss BA. Further portions, RApdirilal filters, a file hash of the file uses comparison mod\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001 #reduce learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "45074/45074 [==============================] - 3132s 69ms/step - loss: 0.5171\n",
      "Epoch 2/3\n",
      "45074/45074 [==============================] - 3020s 67ms/step - loss: 0.3542\n",
      "Epoch 3/3\n",
      "45074/45074 [==============================] - 3041s 67ms/step - loss: 0.3104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3f96e5afd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences_2, np.expand_dims(next_char_2, -1), batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malware detection can based on procedured in this manner, “sinfinulation of the file's sections, the size of the selection of attributes (or constituent data for attribute subsets. In one embodiment, the set of attribute identification module is configured to compute a second hash generation module is configured to generate an aggregate representation of the\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('C:/Users/Gavrilov/My Projects/RNN_LSTM_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malware detection can based on procedured in second hash, the set of file strings and their quantity, the filtered set of strings, the second one will becings to the input of attribute hash generation module is further configured to compute a second hash representing the second set of attributes, the hash function generation module 140 receives hashes of all\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
