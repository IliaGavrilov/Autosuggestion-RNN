{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful model with Keras - long-term dependencies understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Activation, LSTM, Dense, TimeDistributed, Dropout, BatchNormalization\n",
    "from keras.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://lib.ru/LITRA/PUSHKIN/p2.txt'\n",
    "get_url = requests.get(url)\n",
    "text = get_url.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nПТИЧКА\\n\\nВ чужбине свято наблюдаю\\nРодной обычай старины:\\nНа волю птичку выпускаю\\nПри светлом празднике весны.\\n\\nЯ стал доступен утешенью;\\nЗа что на бога мне роптать,\\nКогда хоть одному творенью\\nЯ мог свободу даровать!\\n\\n\\nЦАРСКОЕ СЕЛО\\n\\nХранитель милых чувств и прошлых наслаждений,\\nО ты, певцу дубрав давно знакомый гений,\\nВоспоминание, рисуй передо мной\\nВолшебные места, где я живу душой,\\nЛеса, где я любил, где чувство развивалось,\\nГде с первой юностью младенчество сливалось\\nИ где, взлелеянный природой и мечтой,\\nЯ знал поэзию, веселость и покой...\\n\\nВеди, веди меня под липовые сени,\\nВсегда любезные моей свободной лени,\\nНа берег озера, на тихий скат холмов!..\\nДа вновь увижу я ковры густых лугов,\\nИ дряхлый пук дерев, и светлую долину,\\nИ злачных берегов знакомую картину,\\nИ в тихом озере, средь блещущих зыбей,\\nСтаницу гордую спокойных лебедей.\\n\\n\\n* * *\\n\\nКто, волны, вас остановил,\\nКто оковал ваш бег могучий,\\nКто в пруд безмолвный и дремучий\\nПоток мятежный обратил?\\nЧей жезл волшебный поразил\\nВо мне надежду, скорбь и радость\\nИ душу бурную\\nДремотой лени усыпил?\\nВзыграйте, ветры, взройте воды,\\nРазру'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1180:2280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length:  576904\n"
     ]
    }
   ],
   "source": [
    "print('Corpus length: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz{}АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюя'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  151\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "print(\"Vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_ind = dict((c,i) for i,c in enumerate(chars))\n",
    "#char_ind = {}\n",
    "#for i,c in enumerate(chars):\n",
    "#    char_ind[c]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char indeces:  {'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5, '(': 6, ')': 7, '*': 8, '+': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '<': 26, '=': 27, '>': 28, '?': 29, '@': 30, 'A': 31, 'B': 32, 'C': 33, 'D': 34, 'E': 35, 'F': 36, 'G': 37, 'H': 38, 'I': 39, 'J': 40, 'K': 41, 'L': 42, 'M': 43, 'N': 44, 'O': 45, 'P': 46, 'Q': 47, 'R': 48, 'S': 49, 'T': 50, 'U': 51, 'V': 52, 'W': 53, 'X': 54, 'Y': 55, 'Z': 56, '[': 57, ']': 58, '_': 59, 'a': 60, 'b': 61, 'c': 62, 'd': 63, 'e': 64, 'f': 65, 'g': 66, 'h': 67, 'i': 68, 'j': 69, 'k': 70, 'l': 71, 'm': 72, 'n': 73, 'o': 74, 'p': 75, 'q': 76, 'r': 77, 's': 78, 't': 79, 'u': 80, 'v': 81, 'w': 82, 'x': 83, 'y': 84, 'z': 85, '{': 86, '}': 87, 'А': 88, 'Б': 89, 'В': 90, 'Г': 91, 'Д': 92, 'Е': 93, 'Ж': 94, 'З': 95, 'И': 96, 'Й': 97, 'К': 98, 'Л': 99, 'М': 100, 'Н': 101, 'О': 102, 'П': 103, 'Р': 104, 'С': 105, 'Т': 106, 'У': 107, 'Ф': 108, 'Х': 109, 'Ц': 110, 'Ч': 111, 'Ш': 112, 'Щ': 113, 'Ы': 114, 'Ь': 115, 'Э': 116, 'Ю': 117, 'Я': 118, 'а': 119, 'б': 120, 'в': 121, 'г': 122, 'д': 123, 'е': 124, 'ж': 125, 'з': 126, 'и': 127, 'й': 128, 'к': 129, 'л': 130, 'м': 131, 'н': 132, 'о': 133, 'п': 134, 'р': 135, 'с': 136, 'т': 137, 'у': 138, 'ф': 139, 'х': 140, 'ц': 141, 'ч': 142, 'ш': 143, 'щ': 144, 'ъ': 145, 'ы': 146, 'ь': 147, 'э': 148, 'ю': 149, 'я': 150}\n"
     ]
    }
   ],
   "source": [
    "print('Char indices: ', char_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_char = dict((i,c) for i,c in enumerate(chars))\n",
    "#char_ind = {}\n",
    "#for i,c in enumerate(chars):\n",
    "#    char_ind[i]=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeces of chars:  {0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '&', 5: \"'\", 6: '(', 7: ')', 8: '*', 9: '+', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '<', 27: '=', 28: '>', 29: '?', 30: '@', 31: 'A', 32: 'B', 33: 'C', 34: 'D', 35: 'E', 36: 'F', 37: 'G', 38: 'H', 39: 'I', 40: 'J', 41: 'K', 42: 'L', 43: 'M', 44: 'N', 45: 'O', 46: 'P', 47: 'Q', 48: 'R', 49: 'S', 50: 'T', 51: 'U', 52: 'V', 53: 'W', 54: 'X', 55: 'Y', 56: 'Z', 57: '[', 58: ']', 59: '_', 60: 'a', 61: 'b', 62: 'c', 63: 'd', 64: 'e', 65: 'f', 66: 'g', 67: 'h', 68: 'i', 69: 'j', 70: 'k', 71: 'l', 72: 'm', 73: 'n', 74: 'o', 75: 'p', 76: 'q', 77: 'r', 78: 's', 79: 't', 80: 'u', 81: 'v', 82: 'w', 83: 'x', 84: 'y', 85: 'z', 86: '{', 87: '}', 88: 'А', 89: 'Б', 90: 'В', 91: 'Г', 92: 'Д', 93: 'Е', 94: 'Ж', 95: 'З', 96: 'И', 97: 'Й', 98: 'К', 99: 'Л', 100: 'М', 101: 'Н', 102: 'О', 103: 'П', 104: 'Р', 105: 'С', 106: 'Т', 107: 'У', 108: 'Ф', 109: 'Х', 110: 'Ц', 111: 'Ч', 112: 'Ш', 113: 'Щ', 114: 'Ы', 115: 'Ь', 116: 'Э', 117: 'Ю', 118: 'Я', 119: 'а', 120: 'б', 121: 'в', 122: 'г', 123: 'д', 124: 'е', 125: 'ж', 126: 'з', 127: 'и', 128: 'й', 129: 'к', 130: 'л', 131: 'м', 132: 'н', 133: 'о', 134: 'п', 135: 'р', 136: 'с', 137: 'т', 138: 'у', 139: 'ф', 140: 'х', 141: 'ц', 142: 'ч', 143: 'ш', 144: 'щ', 145: 'ъ', 146: 'ы', 147: 'ь', 148: 'э', 149: 'ю', 150: 'я'}\n"
     ]
    }
   ],
   "source": [
    "print('Indices of chars: ', ind_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_ind[element] for element in text]\n",
    "#idx = []\n",
    "#for element in text:\n",
    "#    element = char_ind[element]\n",
    "#    idx.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26, 67, 79, 72, 71]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of indices:  [[26, 67, 79, 72, 71, 28, 26, 67, 64, 60, 63, 28, 26, 79, 68, 79, 71, 64, 28, 88, 130, 124, 129, 136, 119, 132, 123, 135, 1, 105, 124, 135, 122, 124, 124, 121, 127, 142, 1, 103], [67, 79, 72, 71, 28, 26, 67, 64, 60, 63, 28, 26, 79, 68, 79, 71, 64, 28, 88, 130, 124, 129, 136, 119, 132, 123, 135, 1, 105, 124, 135, 122, 124, 124, 121, 127, 142, 1, 103, 138]]\n",
      "Sequence of indices with train element:  [[67, 79, 72, 71, 28, 26, 67, 64, 60, 63, 28, 26, 79, 68, 79, 71, 64, 28, 88, 130, 124, 129, 136, 119, 132, 123, 135, 1, 105, 124, 135, 122, 124, 124, 121, 127, 142, 1, 103, 138], [79, 72, 71, 28, 26, 67, 64, 60, 63, 28, 26, 79, 68, 79, 71, 64, 28, 88, 130, 124, 129, 136, 119, 132, 123, 135, 1, 105, 124, 135, 122, 124, 124, 121, 127, 142, 1, 103, 138, 143]]\n",
      "Number sentences:  576865\n",
      "Number next char sentences:  576865\n"
     ]
    }
   ],
   "source": [
    "max_len = 40\n",
    "sentences = [idx[elem:elem+max_len] for elem in range(len(idx)-max_len+1)]\n",
    "#sentences = []\n",
    "#for elem in range(0, len(idx)-max_len+1):\n",
    "#    sentences.append(idx[elem: elem+max_len])\n",
    "next_char = [idx[elem+1:elem+max_len+1] for elem in range(len(idx)-max_len+1)]\n",
    "#next_char = []\n",
    "#for elem in range(0, len(idx)-max_len+1):\n",
    "#    next_char.append(elem[item+1: elem+max_len+1])\n",
    "print(\"Sequence of indices: \", sentences[:2])\n",
    "print(\"Sequence of indices with train element: \", next_char[:2])\n",
    "print('Number sentences: ', len(sentences))\n",
    "print('Number next char sentences: ', len(next_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of lists in sentences:  [[ 26  67  79  72  71  28  26  67  64  60  63  28  26  79  68  79  71  64\n",
      "   28  88 130 124 129 136 119 132 123 135   1 105 124 135 122 124 124 121\n",
      "  127 142   1 103]\n",
      " [ 67  79  72  71  28  26  67  64  60  63  28  26  79  68  79  71  64  28\n",
      "   88 130 124 129 136 119 132 123 135   1 105 124 135 122 124 124 121 127\n",
      "  142   1 103 138]]\n",
      "Array of lists in next char:  [[ 67  79  72  71  28  26  67  64  60  63  28  26  79  68  79  71  64  28\n",
      "   88 130 124 129 136 119 132 123 135   1 105 124 135 122 124 124 121 127\n",
      "  142   1 103 138]\n",
      " [ 79  72  71  28  26  67  64  60  63  28  26  79  68  79  71  64  28  88\n",
      "  130 124 129 136 119 132 123 135   1 105 124 135 122 124 124 121 127 142\n",
      "    1 103 138 143]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((576857, 40), (576855, 40))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = np.concatenate([[np.array(elem)] for elem in sentences[:-2]])\n",
    "#np_sentences = np.array([sentences[0]])\n",
    "#for elem in sentences[1:-2]:\n",
    "#    elem = np.array([elem])\n",
    "#    np_sentences = np.concatenate((np_sentences, elem), axis=0)\n",
    "next_char = np.concatenate([[np.array(elem)] for elem in next_char[:-2]])\n",
    "print(\"Array of lists in sentences: \", sentences[:2])\n",
    "print('Array of lists in next char: ', next_char[:2])\n",
    "sentences.shape, next_char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=max_len), #vocab_size is a amount of indices, and indices themselves of course (vertical column of embedding matrix)\n",
    "                                                        #thus vocab_size related to unique char indices in our example\n",
    "                                                        #n_fac is a amount of integers (vector) for every index in vocab_sze (horizontal line of embedding matrix) \n",
    "    BatchNormalization(), #gives well scaled inputs\n",
    "    LSTM(512, return_sequences=True), #return_sequences= says return output every time-step rather than returning single output at the end\n",
    "    Dropout(0.2),\n",
    "    TimeDistributed(Dense(vocab_size)), #TimeDistributed() towards layer in it (Dense layer in this example) \n",
    "                                        #creates copies of that layer, which amount is same as dimension of that layer \n",
    "                                        #every copy will share same weight matrix (vocab_size in this example)\n",
    "                                        #i.e. in Keras if there is return_sequences=True - any Dense layer after that will have to have TD\n",
    "\n",
    "    Activation('softmax')    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 40, 24)            3624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 40, 24)            96        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 40, 512)           1099776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 40, 151)           77463     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 151)           0         \n",
      "=================================================================\n",
      "Total params: 1,180,959\n",
      "Trainable params: 1,180,911\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "576863/576863 [==============================] - 42608s 74ms/step - loss: 1.7514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x931b176e48>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_char, -1), batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_example_2(seed_string):\n",
    "    for i in range(420): #iteration makes prediction character by character #range(value) is a lengh of predicting corpus \n",
    "        x = np.array([char_ind[c] for c in seed_string[-40:]])[np.newaxis,:] #converting seed_string into array of indices\n",
    "        #x = np.array([[char_ind[seed_string[-40]]]]) #[-40] because prediction adding one char to corpus, shifting needed\n",
    "        #for c in seed_string[-39:]: #iteration except char, which is already in array\n",
    "        #    c = np.array([[char_ind[c]]])\n",
    "        #    x = np.concatenate((x, c), axis=1)\n",
    "        \n",
    "        preds=model.predict(x,verbose=0)[0][-1] #[0][-1] because we predicting next char after [-1] value #verbosity mode, 0 or 1. \n",
    "        preds=preds/np.sum(preds) #Array-wise sum devided by element in array #function?\n",
    "        #preds are probabilities associated with each char in shars (amount of 151 floats related to every unique char in chars)\n",
    "        \n",
    "        next_char=np.random.choice(chars,p=preds) #Generates a random sample from chars array \n",
    "                                                  #p:probabilities associated with each entry\n",
    "        #basically random should find best probablility, when with its index we can find its related char in chars dictionary  \n",
    "        #counter=-1\n",
    "        #for elem in np.nditer(preds):\n",
    "        #    counter+=1\n",
    "        #    if elem == np.amax(preds):  #or np.argmax()\n",
    "        #        break\n",
    "        #next_char = chars[counter]\n",
    "        \n",
    "        seed_string=seed_string+next_char #Simply concatenate seed_string\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навис покров угрюмой нощи \n",
      "На своде дремает Байрона\n",
      "Судна того любил он по мнему;\n",
      "Журналист мне светленный,\n",
      "Тем грози церковь участие вершины\n",
      "Лавороски, подарат как перевет.\n",
      "Как он волк, как син. Он вместе в черновик соловей дворянин.\n",
      "\n",
      "Не фарнала в тейра, чки тоще\n",
      "     Да будут  тачен пред ним торкую\n",
      "И к найдушною излованье\n",
      "Воюны за длянет начала крестелить мой орман \"прозил недвижим, по мыслей подаром.\n",
      "\n",
      "\n",
      "* * *\n",
      "Первая мать из, сиды в нем обестели!\n",
      "А сам за\n"
     ]
    }
   ],
   "source": [
    "print_example_2('Навис покров угрюмой нощи \\nНа своде дрем')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('C:/Users/Gavrilov/My projects/LSTM_weights_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж я не тот любовник страстный,\n",
      " Кому диститета роман в Кому книжей заимственный луча,\n",
      "Мласницую мою дорожу\n",
      "Все отвечает подтиром\n",
      "Разбегал в меня робзянье...\n",
      "Клянусь видно, слава  своих,\n",
      "общество, сердце своей праздновался.\n",
      "Неизъясняемой послушной,\n",
      "Ты помнишь ли, о нет не помянеть разона,\n",
      "И само чужой рощу Ику?\n",
      "       И выставил в Бастник.\n",
      "\n",
      "\n",
      "НА ФОСКОМУ\n",
      "\n",
      "Подрежа мнет бренных является взды.. Захладном долгой новой.\n",
      "\n",
      "Он чужкавые сердце моей.\n",
      "\n",
      "Стихи внимал в к\n"
     ]
    }
   ],
   "source": [
    "print_example_2('Уж я не тот любовник страстный,\\n Кому ди')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слыхали ль вы за рощей глас ночной\n",
      " Певца едушенной\".\n",
      "Без обиды, погляд, удалит,\n",
      "Что ты в скалы небесный,\n",
      "Твой долго  на  письма\n",
      "Пушкина, писал о доходе при Павлихо и дане;\n",
      "В мюня, даль его родных\n",
      "листо дни лежалось поздное недурный и привычей.\n",
      "\n",
      "\n",
      "* * *\n",
      "\n",
      "Был и внесть а могилой,\n",
      "Готов вольных меня\n",
      "Не могил глубоком,\n",
      "Тихо любизноваты, други.\n",
      "Благослови.\n",
      "\n",
      "Мой гора и веселья,\n",
      "Покитель твой дорогой\n",
      "Была, чья мудливо и сил же дабого,\n",
      "Серебра на ала ветли жизни пес\n"
     ]
    }
   ],
   "source": [
    "print_example_2('Слыхали ль вы за рощей глас ночной\\n Певца')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
